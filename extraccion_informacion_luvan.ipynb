{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70f19f8",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://www.davivienda.com/wps/portal/personas/nuevo\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/b/b1/Davivienda_logo.svg/1200px-Davivienda_logo.svg.png\" alt=\"Logo\" width=\"300\" height=\"100\">\n",
    "  </a>\n",
    "\n",
    "  <h2 align=\"center\"> Prueba Técniva Davivienda - Profesional I Data no Estructurada</h2>\n",
    "  <h2 align=\"center\"> Notebook de Implementación</h2>\n",
    "  <h4 align=\"center\"> Luvan Tabares </h4>\n",
    "    \n",
    "***\n",
    "\n",
    "  <p align=\"center\">\n",
    "    Realizar la oferta correcta en el momento adecuado es una de las principales estrategias de mercadeo que de manera comprobada aumentan la efectividad de las campañas comerciales. Esta estrategia es conocida como Siguiente Mejor Oferta (NBO) y es generalmente responsabilidad de las áreas de analítica de clientes dado que se construye a partir de modelos analíticos predictivos. En este estudio, se construyeron dos modelos de NBO de productos de crédito para clientes del Banco Davivienda. El primer modelo consistió en un Modelo Experto basado en reglas de negocio y asociaciones estadísticas de las variables independientes y la variable objetivo. El segundo modelo consistió en el entrenamiento de una red neuronal multicapa o Fully Connected. El estudio se basó en una base de datos de clientes del Banco Davivienda y sus aperturas de productos de crédito durante un semestre.  </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "* [1. EDA - Análisis Exploratorio de Datos](#topic1)\n",
    "* [2. Extracción de Nombres](#topic2)\n",
    "* [3. Extracción de Fechas](#topic3)\n",
    "* [4. Extracción de Montos](#topic4)\n",
    "* [5. Extracción de Ciudades](#topic5)\n",
    "* [6. Resultados Finales y Conclusiones](#topic6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b1ab4",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78300d73",
   "metadata": {},
   "source": [
    "Comandos necesarios para la instalación de las librerías utilizadas en este documento, se utilizó el modelo de lenguaje en español grande de spacy para mejorar la detección de las entidades requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7633af49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conda install -c conda-forge pandas==1.2.3\n",
    "# conda install -c conda-forge spacy==3.4.4\n",
    "# !pip uninstall numpy\n",
    "# !pip install numpy\n",
    "# !python -m spacy download es_core_news_lg --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572216f7",
   "metadata": {},
   "source": [
    "## Librerías necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5866d0",
   "metadata": {},
   "source": [
    "Las librerías utilizadas serán 'pandas' para el manejo de los archivos csv y su texto, 'spacy' para la tokenización y todos los procesos de nlp que se apliquen, librería 're' para el uso de expresiones regulares, 'datetime' para la manipulación del formato de fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4b3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from datetime import datetime\n",
    "nlp = spacy.load('es_core_news_lg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93701f5",
   "metadata": {},
   "source": [
    "## 1. **EDA - Análisis Exploratorio de Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5870d9c6",
   "metadata": {},
   "source": [
    "Comenzar con el análisis de la información suministrada, importar el documento teniendo en cuenta el tipo de separador y dar un vistazo al documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305c0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('database/documentos.csv', '|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db5ca40",
   "metadata": {},
   "source": [
    "Se observa un documento de dos columnas y 499 filas, dónde la primer columna (indx 0) es el document_name o nombre del documento, que son números asociados a cada texto, y la segunda columna (indx 1) es la que contiene el texto que nos interesa procesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b4815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>Señor/señora: Daniel Roberto Torres Gómez  L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470</td>\n",
       "      <td>Atención: Ana Miguel Jiménez Rodríguez  Le e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Oiga!!!! Juan Pablo Fernández Muñoz  Esperam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165</td>\n",
       "      <td>Querido/a Carlos Miguel Pérez Pérez,  Espera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>Estimadisimo/a Daniel Cristina Rodríguez Gon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_name                                           document\n",
       "0             86    Señor/señora: Daniel Roberto Torres Gómez  L...\n",
       "1            470    Atención: Ana Miguel Jiménez Rodríguez  Le e...\n",
       "2             16    Oiga!!!! Juan Pablo Fernández Muñoz  Esperam...\n",
       "3            165    Querido/a Carlos Miguel Pérez Pérez,  Espera...\n",
       "4            114    Estimadisimo/a Daniel Cristina Rodríguez Gon..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eac3b3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8787d9",
   "metadata": {},
   "source": [
    "Al analizar uno de los textos se observa que se encuentra la información de interés como nombre, monto, fecha y ciudad, el orden de estos no siempre es así, teniendo casos en los que el nombre se encuentra al final o no existe una ciudad de residencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fc3b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Atención: Ana Miguel Jiménez Rodríguez  Le escribimos para informarle que tiene un saldo a favor nuestro de £ 6,487,447,022.84 en su cuenta con nuestra empresa. Como puede recordar, tomó un préstamo con nosotros para   adquirir un auto de lujo Bentley Aventador en San Andrés. A pesar de múltiples intentos de ponerse en contacto con usted y recordarle su deuda pendiente, no hemos recibido ninguna respuesta   ni pago de su parte. Por lo tanto, solicitamos que devuelva el auto a nosotros o pague la totalidad de su deuda lo antes posible. Si no toma medidas en este asunto,   nos veremos obligados a iniciar acciones legales para recuperar la totalidad de su deuda.     Le instamos a que se ponga en contacto con nosotros lo antes posible para   discutir acuerdos de pago y evitar acciones legales adicionales, su deuda esta desde el 01/22/2016.     Si está experimentando dificultades financieras y no puede pagar la   totalidad de su deuda en este momento, no dude en ponerse en contacto con nosotros para discutir acuerdos de pago. Estamos dispuestos a trabajar con usted para   encontrar una solución justa y razonable para ambas partes.  Esperamos tener noticias suyas pronto y organizar una sesión de yoga y meditación colectiva para calmar los ánimos y encontrar una solución sana y equilibrada a este asunto.  Fake Incorporated quiere recordarle de manera amistosa que es hora de ponerse al día con sus pagos. ¡No se preocupe, tenemos muchas opciones   para ayudarle a encontrar una solución que funcione para usted!    Gracias por su atención oportuna a este asunto.  Globex Industries  Dirección Avenida mentira 456, Bogotá, Colombia  Teléfono +57 363 4381826  website www.globex_industries.com.co    '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['document'][1] # Exploramos uno de los textos a analizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8788ada",
   "metadata": {},
   "source": [
    "## Estudio de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2739c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf86840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449c34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d87a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4e4f63b",
   "metadata": {},
   "source": [
    "## Funciones necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d8980",
   "metadata": {},
   "source": [
    "Dentro de la teoría básica de procesamiento de lenguaje natural nos encontraremos con las siguientes opciones de preprocesamiento:\n",
    "\n",
    "1.Tokenización\n",
    "2.Convertir texto a minúsculas \n",
    "3.Remover palabras de parada/artículos (Stop Words)\n",
    "4.Remover puntuación\n",
    "5.Estemización\n",
    "6.Lematización\n",
    "\n",
    "Para la tokenización se usará la librería 'spacy' y siempre se necesitará tokenizar el texto para su análisis, las otras opciones de preprocesamiento pueden ser usadas o no dependiendo de cómo se comporte el modelo, ya que para el análisis de este documento se observó que convertir a minúsculas llevaba a un error mayor en la identificación de las palabras (NER) y para cierta extracción de información se pueden usar diferentes combinaciones de preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40640382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.text for token in doc if not token.like_url])\n",
    "\n",
    "def remove_stop(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.text for token in doc if not token.is_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5ab3c",
   "metadata": {},
   "source": [
    "Para este caso de análisis se observó que remover puntuación, convertir a minúsculas y lematizar empeoraban la capacidad de detección de entidades (NER) de spacy, muy probablemente por que para la detección analiza si las palabras empiezan por letra mayúscula y la puntuación y no lematizar le ayudan a detectar mejor el contexto. No se contempló usar estemización ya que conlleva a la creación de palabras que no existen el idioma, en un intento de obtener la raíz de la palabra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe00c71",
   "metadata": {},
   "source": [
    "# 2. Extracción de Nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abbe0f",
   "metadata": {},
   "source": [
    "Como primer paso de extracción se realizará la extracción de los nombres presentes en el documento, la librería spacy los detectará con la etiqueta 'PER' y analizando los documentos se observó que los nombres empiezan por letra mayúscula y son nombre compuestos, es decir dos nombres dos apellidos, pero se tuvo en cuenta el caso de personas con un sólo nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8832199",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('hola')\n",
    "nlp.Defaults.stop_words.add('estimado')\n",
    "nlp.Defaults.stop_words.add('estimada')\n",
    "nlp.Defaults.stop_words.add('estimadísimo')\n",
    "nlp.Defaults.stop_words.add('estimadísima')\n",
    "nlp.Defaults.stop_words.add('don')\n",
    "nlp.Defaults.stop_words.add('doña')\n",
    "nlp.Defaults.stop_words.add('amigo')\n",
    "nlp.Defaults.stop_words.add('amiga')\n",
    "nlp.Defaults.stop_words.add('esperamos')\n",
    "nlp.Defaults.stop_words.add('queridísimo')\n",
    "nlp.Defaults.stop_words.add('queridísima')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd55708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"document\"].str.replace('oiga', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d2a77",
   "metadata": {},
   "source": [
    "En las dos celdas de arriba se empezó a agregar palabras que interferían con la detección de spacy y que se podrían considerar como Stop Words para este análisis ya que no nos suministran información relevante, la palabra oiga no estaba siendo eliminada usando la remoción de stop words por lo que se utilizó un replace para eliminarla forzosamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc92bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"text_nlp\"].apply(remove_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d24ce",
   "metadata": {},
   "source": [
    "La eliminación de la palabra 'oiga' también me permite crear una nueva columna para la manipulación de la información sin cambiar el texto original y poder llamarlo de nuevo en caso de ser necesario, y ahora si aplico la remoción de Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21cdff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names4 = r'[A-ZÁÉÍÓÚÑa-záéíóúñ]+\\s[A-ZÁÉÍÓÚÑa-záéíóúñ]+\\s[A-ZÁÉÍÓÚÑa-záéíóúñ]+\\s[A-ZÁÉÍÓÚÑa-záéíóúñ]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab54c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names3 = r'[A-ZÁÉÍÓÚÑa-záéíóúñ]+\\s[A-ZÁÉÍÓÚÑa-záéíóúñ]+\\s[A-ZÁÉÍÓÚÑa-záéíóúñ]+'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56d6b6",
   "metadata": {},
   "source": [
    "Como se mencionó anteriormente consideré que existen dos nombres, compuestos y simples, dónde los compuestos tendrán 4 palabras que empizan por letra mayúscula y los simples es lo mismo pero con 3 palabras. Se tuvo en cuenta tíldes y la letra ñ propios de nuestro lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea6ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(text):\n",
    "            \n",
    "    doc = nlp(text)  \n",
    "\n",
    "    for ent in doc.ents:          \n",
    "        if ent.label_ == \"PER\":\n",
    "            if re.search(names4, ent.text) or re.search(names3, ent.text):\n",
    "                q = ent.text.replace('   carta', '').replace('¡ !', '').replace('   ', '')\n",
    "\n",
    "                name = q\n",
    "                                   \n",
    "                break\n",
    "            else:\n",
    "                name = 'No encontrado'\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3be421",
   "metadata": {},
   "source": [
    "La función extract_names recibirá el texto correspondiente a cada fila y aplicará tokenización (nlp(text)), al tokenizar se pueden usar las funciones de spacy y convierte el texto str a una lista con cada palabra o grupo de palabras tokenizadas, en dónde spacy le dará unas etiquetas o TAG's conociendo que la etiqueta de personas o nombres se llama 'PER' busco en la lista cada token que tenga la etiqueta PER y reviso si tienen la forma de un nombre simple o compuesto y realizo una limpieza final de algunos elementos que tomaba como parte de la etique. En caso de que no encuentre un token que satisfaga las condiciones devolverá 'No encontrado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nombre_cliente'] = df['text_nlp'].apply(extract_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4b49e",
   "metadata": {},
   "source": [
    "## 3. Extracción de Fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74a30a",
   "metadata": {},
   "source": [
    "Para la extracción de las fechas se observó mejor comportamiento al usar de nuevo el documento desde el principio, por lo que se reescribirá la columna 'text_nlp' del csv por una no procesada, cuyo único preprocesamiento será la eliminación de espacios alargados en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e190bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"document\"].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c944e1",
   "metadata": {},
   "source": [
    "Se eliminan los espacios alargados en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c47d2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fechapat = r'([\\d]{4}(\\-|\\/|\\_)[\\d]{2}(\\-|\\/|\\_)[\\d]{2})|([\\d]{2}(\\-|\\/|\\_)[\\d]{2}(\\-|\\/|\\_)[\\d]{4})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977cdd4",
   "metadata": {},
   "source": [
    "Este es el regex propuesto para la detección de las fechas, revisando algunos documentos se observó que tenían dos formatos, AÑO-mes-día y mes/día/año, por lo que el regex detecta si es primer o segundo patrón y dependiendo de qué patrón muestre la fecha se procesará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c57da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(text):\n",
    "\n",
    "\n",
    "    match = re.search(fechapat, text)\n",
    "\n",
    "    \n",
    "    number = match.group()\n",
    "    \n",
    "    if number:\n",
    "        if \"-\" in number:\n",
    "\n",
    "            date = datetime.strptime(number, \"%Y-%m-%d\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            date = datetime.strptime(number, \"%m/%d/%Y\")\n",
    "\n",
    "\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        day = date.day    \n",
    "\n",
    "\n",
    "        today = datetime(year, month, day) #(YEAR, MONTH, DAY)\n",
    "\n",
    "        fchas = f'{today:%Y}-{today:%m}-{today:%d}'\n",
    "    \n",
    "    else:\n",
    "        fchas = 'No encontrado'\n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "    return fchas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499c89a",
   "metadata": {},
   "source": [
    "Este código analizará si en el texto existe un patrón de fecha anteriormente mencionado, si existe extraerá la fecha y será procesada dependiendo del formato, una vez se procesa se obtiene el año, el mes y el día usando datetime. Ahora que tenemos separado quién es año, mes y día se vuelve a usar datetime y se escribe con el formato solicitado AÑO-mes-día, en caso de no encontrar un patrón devolverá 'No encontrado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha'] = df['text_nlp'].apply(extract_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496ea5e",
   "metadata": {},
   "source": [
    "## 4. Extracción de Montos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca2b20",
   "metadata": {},
   "source": [
    "Para la extracción de montos se utilizará el mismo texto que en el caso de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd63f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpat = r'[\\d]{0,3}(\\,|\\.)?[\\d]{0,3}(\\,|\\.)?[\\d]{0,3}(\\,|\\.)?[\\d]{1,3}(\\,|\\.)[\\d]{1,2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4653d3",
   "metadata": {},
   "source": [
    "Se creó un regex que cumpliera con la condición de estar separado por puntos o comas y tener entre 0 a 3 dígitos por sección entre puntos y comas, es decir detectará números como 111,111,111.11 ó 1,111,111.11. Se mantuvo una restricción de terminar en punto ya que todos los documentos presentaban ese patrón, además de 2 cifras decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3990e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_money(text):\n",
    "\n",
    "\n",
    "    match = re.search(numpat, text)\n",
    "\n",
    "    if match:\n",
    "        number = match.group()\n",
    "\n",
    "        m = number.replace(',', '/').replace('.', ',').replace('/', '')\n",
    "\n",
    "        mone = m\n",
    "    else:\n",
    "        mone = 'No encontrado'\n",
    "    \n",
    "    return mone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da2339",
   "metadata": {},
   "source": [
    "Para extraer el monto es muy similar a extraer la fecha, se revisa si en el texto existe el patrón y si hay patrón se extrae ese número, posteriormente se cambian las comas por barra oblicua (slash), luego se reemplazan los puntos por comas y se eliminan los slash, para así entregar el monto en el formato solicitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['monto'] = df['text_nlp'].apply(extract_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b6d48",
   "metadata": {},
   "source": [
    "## 5. Extracción de Ciudades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b07ed",
   "metadata": {},
   "source": [
    "En el caso de la extracción de ciudades por seguridad se volvió a tomar el documento original y se preprocesará eliminado espacios y algunas Stop Words indeseadas, no se eliminaron las Stop Words por el método anterior en nombres ya que la eliminación de las Stop Words comunes empeoraba la detección del spacy, por lo que se utilizó el replace para hacer una remoción de Stop Words un poco más específica, además que se notó una mejoría en la detección al aplicar el removedor de url al texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd8fe1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"document\"].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda143cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"text_nlp\"].str.replace('Nos', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f163f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"text_nlp\"].str.replace('Initech', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e72807dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_nlp\"] = df[\"text_nlp\"].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "785467c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudad1 = r'([A-Z])([a-záéíóúñ]+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d0596",
   "metadata": {},
   "source": [
    "Para el caso de comparar si lo encontrado es una ciudad lo ideal sería compararlo con una lista de todas las ciudades de colombia, pero por cuestiones de tiempo se decidió utilizar un regex que simplemente detectara una palabra que empezara por letra mayúscula ya que se observó que las ciudades son palabras simples o compuestas pero empiezan por una letra maýuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "959eee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(text):\n",
    "\n",
    "        doc = nlp(text) \n",
    "        \n",
    "        for ent in doc.ents:          \n",
    "            if ent.label_ == \"LOC\":\n",
    "                \n",
    "                q = ent.text\n",
    "                if q == 'Bogotá':\n",
    "                    q = 'No encontrado'\n",
    "                elif re.search(ciudad1, q) is None:\n",
    "                    q = 'No encontrado'\n",
    "\n",
    "                cet = q\n",
    "                       \n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        return cet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfc872",
   "metadata": {},
   "source": [
    "La función extraerá el texto y lo tokenizará, luego podemos revisar si estos token son una 'LOC' que se refiera a las ciudades o lugares, posteriormente se analiza si la ciudad es Bogotá o no, aunque hacer esta aseveración realmente sería un error se observó en los documentos que todas las cartas eran enviadas desde Bogotá por lo que Bogotá se podría considerar una Stop Word, lo ideal sería comparar con una lista de ciudades de colombia, además de revisar si hay más de 1 token 'LOC' en el texto, si sólo hay un token 'LOC' muy probablemente sea la ciudad de la empresa y no la ciudad de la persona a la cuál se le está cobrando. Entonces aquí se analizó como que en caso de la 'LOC' sea Bogotá lo tome como 'No encontrado' y en caso de que no encuentre token con la etiqueta 'LOC' devuelva 'No encontrado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ciudad'] = df['text_nlp'].apply(extract_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88d0c1",
   "metadata": {},
   "source": [
    "## Resultados Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc8011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcb8c2f2",
   "metadata": {},
   "source": [
    "Aquí se llaman cada una de las funciones y se crea una nueva columna con dicha información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78488f80",
   "metadata": {},
   "source": [
    "## Arreglo de la tabla final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abaaa7",
   "metadata": {},
   "source": [
    "Para terminar, el archivo csv quedó con el orden incorrecto ya que se llamaron las funciones en el orden presentado, con el código de abajo se va a cambiar de posición la última columna de ciudades a su posición además de renombrar las columnas suministradas por el formato deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd547e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['text_nlp'])\n",
    "column_name = 'ciudad'\n",
    "new_pos = 3\n",
    "column_names = list(df.columns)\n",
    "column_names.remove(column_name)\n",
    "column_names.insert(new_pos, column_name)\n",
    "df = df[column_names]\n",
    "df = df.rename(columns={'document_name': 'nombre_documento'})\n",
    "df = df.rename(columns={'document': 'texto'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f432d6",
   "metadata": {},
   "source": [
    "Presentamos la tabla dónde se observa que quedó con el formato solicitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eac29df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_documento</th>\n",
       "      <th>texto</th>\n",
       "      <th>nombre_cliente</th>\n",
       "      <th>ciudad</th>\n",
       "      <th>fecha</th>\n",
       "      <th>monto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>Señor/señora: Daniel Roberto Torres Gómez  L...</td>\n",
       "      <td>Daniel Roberto Torres Gómez</td>\n",
       "      <td>Zaragoza</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>6287918586,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470</td>\n",
       "      <td>Atención: Ana Miguel Jiménez Rodríguez  Le e...</td>\n",
       "      <td>Ana Miguel Jiménez Rodríguez</td>\n",
       "      <td>San Andrés</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>6487447022,84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Oiga!!!! Juan Pablo Fernández Muñoz  Esperam...</td>\n",
       "      <td>Juan Pablo Fernández Muñoz</td>\n",
       "      <td>Girón</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>199967325,33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165</td>\n",
       "      <td>Querido/a Carlos Miguel Pérez Pérez,  Espera...</td>\n",
       "      <td>Carlos Miguel Pérez Pérez</td>\n",
       "      <td>Popayán</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>825558525,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>Estimadisimo/a Daniel Cristina Rodríguez Gon...</td>\n",
       "      <td>Daniel Cristina Rodríguez González</td>\n",
       "      <td>Puerto Leguízamo</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>1005623583,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119</td>\n",
       "      <td>A quien corresponda,    Ha llegado a nuestra...</td>\n",
       "      <td>Juan Santiago Santos Méndez</td>\n",
       "      <td>No encontrado</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>1281162307,55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>136</td>\n",
       "      <td>¡Hola querido/a Pedro Isabel Torres Alonso! ...</td>\n",
       "      <td>Pedro Isabel Torres Alonso</td>\n",
       "      <td>Ocana</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>9357233710,93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>337</td>\n",
       "      <td>Estimado/a: Laura Patricia Fernández Ruiz  H...</td>\n",
       "      <td>Laura Patricia Fernández Ruiz</td>\n",
       "      <td>Ibagué</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>3321107382,06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>234</td>\n",
       "      <td>Señor/señora: Fernando María Rodríguez Alons...</td>\n",
       "      <td>Fernando María Rodríguez Alonso</td>\n",
       "      <td>Montelíbano</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>2001793770,50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>498</td>\n",
       "      <td>¡Hola! Fernando Daniel Hernández García ¿Qué...</td>\n",
       "      <td>Fernando Daniel Hernández García</td>\n",
       "      <td>Pasto</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>8777175239,78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>394</td>\n",
       "      <td>Señor/señora: Álvaro Miguel Ruiz Díaz  Le es...</td>\n",
       "      <td>Álvaro Miguel Ruiz Díaz</td>\n",
       "      <td>No encontrado</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>2483866437,70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>173</td>\n",
       "      <td>Estimado/a: Sandra Samantha Hernández Gonzál...</td>\n",
       "      <td>Sandra Samantha Hernández González</td>\n",
       "      <td>Planeta Rica</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>984169377,80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>Señor/señora: Pedro Laura Torres García  Le ...</td>\n",
       "      <td>Pedro Laura Torres García</td>\n",
       "      <td>Cartagena</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>9628666584,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>379</td>\n",
       "      <td>Estimado/a: Daniel María Fernández Méndez  H...</td>\n",
       "      <td>Daniel María Fernández Méndez</td>\n",
       "      <td>Ibagué</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>5607719277,34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>105</td>\n",
       "      <td>Estimadisimo/a Sandra Miguel Torres Alonso, ...</td>\n",
       "      <td>Sandra Miguel Torres Alonso</td>\n",
       "      <td>Palmira</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>4012413608,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>246</td>\n",
       "      <td>¡Hola! Álvaro María Alonso Muñoz ¿Qué tal es...</td>\n",
       "      <td>Álvaro María Alonso Muñoz</td>\n",
       "      <td>Bucaramanga</td>\n",
       "      <td>2013-10-17</td>\n",
       "      <td>7214484003,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>286</td>\n",
       "      <td>Queridísimo/a Álvaro Laura Pérez Hernández, ...</td>\n",
       "      <td>Álvaro Laura Pérez Hernández</td>\n",
       "      <td>Riohacha</td>\n",
       "      <td>2015-09-04</td>\n",
       "      <td>2462370708,97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>198</td>\n",
       "      <td>Estimado/a: Samantha Pablo Díaz Martínez  Ha...</td>\n",
       "      <td>Samantha Pablo Díaz Martínez</td>\n",
       "      <td>Buenaventura</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>5985743017,57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>377</td>\n",
       "      <td>A quien corresponda,    Ha llegado a nuestra...</td>\n",
       "      <td>Fernando Laura García García</td>\n",
       "      <td>No encontrado</td>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>2382735039,73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45</td>\n",
       "      <td>Atención: Daniel Sara Santos González  Le es...</td>\n",
       "      <td>Daniel Sara Santos González</td>\n",
       "      <td>Tumaco</td>\n",
       "      <td>2015-05-24</td>\n",
       "      <td>7841683747,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>240</td>\n",
       "      <td>¡Hola! Juan Pablo Santos Lopez ¿Qué tal está...</td>\n",
       "      <td>Juan Pablo Santos Lopez</td>\n",
       "      <td>Tumaco</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>5422933580,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>247</td>\n",
       "      <td>¡Hola! Gloria María Romero Alonso ¿Qué tal e...</td>\n",
       "      <td>Gloria María Romero Alonso</td>\n",
       "      <td>Itagüí</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>5051416524,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>196</td>\n",
       "      <td>Estimado/a: Sandra Sandra Gómez Torres  Ha l...</td>\n",
       "      <td>Sandra Sandra Gómez Torres</td>\n",
       "      <td>Cartagena</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>2982475236,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>193</td>\n",
       "      <td>Estimado/a: María Pablo García Torres  Ha ll...</td>\n",
       "      <td>María Pablo García Torres</td>\n",
       "      <td>Manizales</td>\n",
       "      <td>2016-02-28</td>\n",
       "      <td>4037426895,43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>429</td>\n",
       "      <td>Estimadisimo/a Patricia Gloria González Rome...</td>\n",
       "      <td>Patricia Gloria González Romero</td>\n",
       "      <td>San Andrés</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>1779351916,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>345</td>\n",
       "      <td>Señor/señora: Gloria Sara Méndez García  Le ...</td>\n",
       "      <td>Gloria Sara Méndez García</td>\n",
       "      <td>Tame</td>\n",
       "      <td>2015-05-17</td>\n",
       "      <td>1034583314,64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nombre_documento                                              texto  \\\n",
       "0                 86    Señor/señora: Daniel Roberto Torres Gómez  L...   \n",
       "1                470    Atención: Ana Miguel Jiménez Rodríguez  Le e...   \n",
       "2                 16    Oiga!!!! Juan Pablo Fernández Muñoz  Esperam...   \n",
       "3                165    Querido/a Carlos Miguel Pérez Pérez,  Espera...   \n",
       "4                114    Estimadisimo/a Daniel Cristina Rodríguez Gon...   \n",
       "5                119    A quien corresponda,    Ha llegado a nuestra...   \n",
       "6                136    ¡Hola querido/a Pedro Isabel Torres Alonso! ...   \n",
       "7                337    Estimado/a: Laura Patricia Fernández Ruiz  H...   \n",
       "8                234    Señor/señora: Fernando María Rodríguez Alons...   \n",
       "9                498    ¡Hola! Fernando Daniel Hernández García ¿Qué...   \n",
       "10               394    Señor/señora: Álvaro Miguel Ruiz Díaz  Le es...   \n",
       "11               173    Estimado/a: Sandra Samantha Hernández Gonzál...   \n",
       "12               400    Señor/señora: Pedro Laura Torres García  Le ...   \n",
       "13               379    Estimado/a: Daniel María Fernández Méndez  H...   \n",
       "14               105    Estimadisimo/a Sandra Miguel Torres Alonso, ...   \n",
       "15               246    ¡Hola! Álvaro María Alonso Muñoz ¿Qué tal es...   \n",
       "16               286    Queridísimo/a Álvaro Laura Pérez Hernández, ...   \n",
       "17               198    Estimado/a: Samantha Pablo Díaz Martínez  Ha...   \n",
       "18               377    A quien corresponda,    Ha llegado a nuestra...   \n",
       "19                45    Atención: Daniel Sara Santos González  Le es...   \n",
       "20               240    ¡Hola! Juan Pablo Santos Lopez ¿Qué tal está...   \n",
       "21               247    ¡Hola! Gloria María Romero Alonso ¿Qué tal e...   \n",
       "22               196    Estimado/a: Sandra Sandra Gómez Torres  Ha l...   \n",
       "23               193    Estimado/a: María Pablo García Torres  Ha ll...   \n",
       "24               429    Estimadisimo/a Patricia Gloria González Rome...   \n",
       "25               345    Señor/señora: Gloria Sara Méndez García  Le ...   \n",
       "\n",
       "                        nombre_cliente            ciudad       fecha  \\\n",
       "0          Daniel Roberto Torres Gómez          Zaragoza  2020-01-30   \n",
       "1         Ana Miguel Jiménez Rodríguez        San Andrés  2016-01-22   \n",
       "2           Juan Pablo Fernández Muñoz             Girón  2017-12-25   \n",
       "3            Carlos Miguel Pérez Pérez           Popayán  2016-07-25   \n",
       "4   Daniel Cristina Rodríguez González  Puerto Leguízamo  2016-01-27   \n",
       "5          Juan Santiago Santos Méndez     No encontrado  2018-02-06   \n",
       "6           Pedro Isabel Torres Alonso             Ocana  2017-02-08   \n",
       "7        Laura Patricia Fernández Ruiz            Ibagué  2019-01-23   \n",
       "8      Fernando María Rodríguez Alonso       Montelíbano  2017-03-27   \n",
       "9     Fernando Daniel Hernández García             Pasto  2016-05-09   \n",
       "10             Álvaro Miguel Ruiz Díaz     No encontrado  2017-11-15   \n",
       "11  Sandra Samantha Hernández González      Planeta Rica  2017-05-09   \n",
       "12           Pedro Laura Torres García         Cartagena  2016-07-25   \n",
       "13       Daniel María Fernández Méndez            Ibagué  2019-07-17   \n",
       "14         Sandra Miguel Torres Alonso           Palmira  2021-12-24   \n",
       "15           Álvaro María Alonso Muñoz       Bucaramanga  2013-10-17   \n",
       "16        Álvaro Laura Pérez Hernández          Riohacha  2015-09-04   \n",
       "17        Samantha Pablo Díaz Martínez      Buenaventura  2019-06-04   \n",
       "18        Fernando Laura García García     No encontrado  2014-09-21   \n",
       "19         Daniel Sara Santos González            Tumaco  2015-05-24   \n",
       "20             Juan Pablo Santos Lopez            Tumaco  2018-05-04   \n",
       "21          Gloria María Romero Alonso            Itagüí  2015-04-22   \n",
       "22          Sandra Sandra Gómez Torres         Cartagena  2018-09-08   \n",
       "23           María Pablo García Torres         Manizales  2016-02-28   \n",
       "24     Patricia Gloria González Romero        San Andrés  2020-09-23   \n",
       "25           Gloria Sara Méndez García              Tame  2015-05-17   \n",
       "\n",
       "            monto  \n",
       "0   6287918586,38  \n",
       "1   6487447022,84  \n",
       "2    199967325,33  \n",
       "3    825558525,29  \n",
       "4   1005623583,51  \n",
       "5   1281162307,55  \n",
       "6   9357233710,93  \n",
       "7   3321107382,06  \n",
       "8   2001793770,50  \n",
       "9   8777175239,78  \n",
       "10  2483866437,70  \n",
       "11   984169377,80  \n",
       "12  9628666584,41  \n",
       "13  5607719277,34  \n",
       "14  4012413608,75  \n",
       "15  7214484003,61  \n",
       "16  2462370708,97  \n",
       "17  5985743017,57  \n",
       "18  2382735039,73  \n",
       "19  7841683747,16  \n",
       "20  5422933580,05  \n",
       "21  5051416524,39  \n",
       "22  2982475236,10  \n",
       "23  4037426895,43  \n",
       "24  1779351916,04  \n",
       "25  1034583314,64  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd2bee",
   "metadata": {},
   "source": [
    "Y se exporta el archivo csv con el separador '|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b8500d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('resultados.csv', sep = '|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
